{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "da9cc23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "np.set_printoptions(threshold=10000,suppress=True) \n",
    "import pandas as pd\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt \n",
    "warnings.filterwarnings('ignore')\n",
    "import gensim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Dense, LSTM, Bidirectional\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010826fd",
   "metadata": {},
   "source": [
    "<h1 align=center><font size = 5 color='blue'>Chargement et préparation des données</font></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "31d805d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>abstractText</th>\n",
       "      <th>meshMajor</th>\n",
       "      <th>pmid</th>\n",
       "      <th>meshid</th>\n",
       "      <th>meshroot</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "      <th>G</th>\n",
       "      <th>H</th>\n",
       "      <th>I</th>\n",
       "      <th>J</th>\n",
       "      <th>L</th>\n",
       "      <th>M</th>\n",
       "      <th>N</th>\n",
       "      <th>Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Expression of p53 and coexistence of HPV in pr...</td>\n",
       "      <td>Fifty-four paraffin embedded tissue sections f...</td>\n",
       "      <td>['DNA Probes, HPV', 'DNA, Viral', 'Female', 'H...</td>\n",
       "      <td>8549602</td>\n",
       "      <td>[['D13.444.600.223.555', 'D27.505.259.750.600....</td>\n",
       "      <td>['Chemicals and Drugs [D]', 'Organisms [B]', '...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Vitamin D status in pregnant Indian women acro...</td>\n",
       "      <td>The present cross-sectional study was conducte...</td>\n",
       "      <td>['Adult', 'Alkaline Phosphatase', 'Breast Feed...</td>\n",
       "      <td>21736816</td>\n",
       "      <td>[['M01.060.116'], ['D08.811.277.352.650.035'],...</td>\n",
       "      <td>['Named Groups [M]', 'Chemicals and Drugs [D]'...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Identification of a functionally important di...</td>\n",
       "      <td>The occurrence of individual amino acids and d...</td>\n",
       "      <td>['Amino Acid Sequence', 'Analgesics, Opioid', ...</td>\n",
       "      <td>19060934</td>\n",
       "      <td>[['G02.111.570.060', 'L01.453.245.667.060'], [...</td>\n",
       "      <td>['Phenomena and Processes [G]', 'Information S...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Multilayer capsules: a promising microencapsul...</td>\n",
       "      <td>In 1980, Lim and Sun introduced a microcapsule...</td>\n",
       "      <td>['Acrylic Resins', 'Alginates', 'Animals', 'Bi...</td>\n",
       "      <td>11426874</td>\n",
       "      <td>[['D05.750.716.822.111', 'D25.720.716.822.111'...</td>\n",
       "      <td>['Chemicals and Drugs [D]', 'Technology, Indus...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nanohydrogel with N,N'-bis(acryloyl)cystine cr...</td>\n",
       "      <td>Substantially improved hydrogel particles base...</td>\n",
       "      <td>['Antineoplastic Agents', 'Cell Proliferation'...</td>\n",
       "      <td>28323099</td>\n",
       "      <td>[['D27.505.954.248'], ['G04.161.750', 'G07.345...</td>\n",
       "      <td>['Chemicals and Drugs [D]', 'Phenomena and Pro...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A new &lt;i&gt;Panolis&lt;/i&gt; H?bner, [1821] species fr...</td>\n",
       "      <td>Panolis is a well-defined and compact Palearct...</td>\n",
       "      <td>['Animal Distribution', 'Animals', 'Asia', 'La...</td>\n",
       "      <td>28609947</td>\n",
       "      <td>[['F01.145.113.069', 'G16.049'], ['B01.050'], ...</td>\n",
       "      <td>['Psychiatry and Psychology [F]', 'Phenomena a...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Characterization of neutron field in a NPP wor...</td>\n",
       "      <td>At the Krsko Nuclear Power Plant (NPP), albedo...</td>\n",
       "      <td>['Algorithms', 'Equipment Design', 'Equipment ...</td>\n",
       "      <td>17416593</td>\n",
       "      <td>[['G17.035', 'L01.224.050'], ['E05.320'], ['E0...</td>\n",
       "      <td>['Phenomena and Processes [G]', 'Information S...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Tramadol vs dexmedetomidine for emergence agit...</td>\n",
       "      <td>BACKGROUND: This study was designed to compare...</td>\n",
       "      <td>['Adenoidectomy', 'Airway Extubation', 'Analge...</td>\n",
       "      <td>28283018</td>\n",
       "      <td>[['E04.580.068'], ['E02.041.249', 'E05.008'], ...</td>\n",
       "      <td>['Analytical, Diagnostic and Therapeutic Techn...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Nucleotide diphosphates activate the ATP-sensi...</td>\n",
       "      <td>Patch-clamp techniques were used to study the ...</td>\n",
       "      <td>['Adenosine Diphosphate', 'Adenosine Triphosph...</td>\n",
       "      <td>1488275</td>\n",
       "      <td>[['D03.633.100.759.646.138.124', 'D13.695.667....</td>\n",
       "      <td>['Chemicals and Drugs [D]', 'Organisms [B]', '...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Using Standardized Checklists Increase the Com...</td>\n",
       "      <td>INTRODUCTION: Hospital evacuations of patients...</td>\n",
       "      <td>['Checklist', 'Civil Defense', 'Emergencies', ...</td>\n",
       "      <td>31389323</td>\n",
       "      <td>[['N05.715.360.300.179'], ['I01.451.227'], ['C...</td>\n",
       "      <td>['Health Care [N]', 'Anthropology, Education, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0  Expression of p53 and coexistence of HPV in pr...   \n",
       "1  Vitamin D status in pregnant Indian women acro...   \n",
       "2  [Identification of a functionally important di...   \n",
       "3  Multilayer capsules: a promising microencapsul...   \n",
       "4  Nanohydrogel with N,N'-bis(acryloyl)cystine cr...   \n",
       "5  A new <i>Panolis</i> H?bner, [1821] species fr...   \n",
       "6  Characterization of neutron field in a NPP wor...   \n",
       "7  Tramadol vs dexmedetomidine for emergence agit...   \n",
       "8  Nucleotide diphosphates activate the ATP-sensi...   \n",
       "9  Using Standardized Checklists Increase the Com...   \n",
       "\n",
       "                                        abstractText  \\\n",
       "0  Fifty-four paraffin embedded tissue sections f...   \n",
       "1  The present cross-sectional study was conducte...   \n",
       "2  The occurrence of individual amino acids and d...   \n",
       "3  In 1980, Lim and Sun introduced a microcapsule...   \n",
       "4  Substantially improved hydrogel particles base...   \n",
       "5  Panolis is a well-defined and compact Palearct...   \n",
       "6  At the Krsko Nuclear Power Plant (NPP), albedo...   \n",
       "7  BACKGROUND: This study was designed to compare...   \n",
       "8  Patch-clamp techniques were used to study the ...   \n",
       "9  INTRODUCTION: Hospital evacuations of patients...   \n",
       "\n",
       "                                           meshMajor      pmid  \\\n",
       "0  ['DNA Probes, HPV', 'DNA, Viral', 'Female', 'H...   8549602   \n",
       "1  ['Adult', 'Alkaline Phosphatase', 'Breast Feed...  21736816   \n",
       "2  ['Amino Acid Sequence', 'Analgesics, Opioid', ...  19060934   \n",
       "3  ['Acrylic Resins', 'Alginates', 'Animals', 'Bi...  11426874   \n",
       "4  ['Antineoplastic Agents', 'Cell Proliferation'...  28323099   \n",
       "5  ['Animal Distribution', 'Animals', 'Asia', 'La...  28609947   \n",
       "6  ['Algorithms', 'Equipment Design', 'Equipment ...  17416593   \n",
       "7  ['Adenoidectomy', 'Airway Extubation', 'Analge...  28283018   \n",
       "8  ['Adenosine Diphosphate', 'Adenosine Triphosph...   1488275   \n",
       "9  ['Checklist', 'Civil Defense', 'Emergencies', ...  31389323   \n",
       "\n",
       "                                              meshid  \\\n",
       "0  [['D13.444.600.223.555', 'D27.505.259.750.600....   \n",
       "1  [['M01.060.116'], ['D08.811.277.352.650.035'],...   \n",
       "2  [['G02.111.570.060', 'L01.453.245.667.060'], [...   \n",
       "3  [['D05.750.716.822.111', 'D25.720.716.822.111'...   \n",
       "4  [['D27.505.954.248'], ['G04.161.750', 'G07.345...   \n",
       "5  [['F01.145.113.069', 'G16.049'], ['B01.050'], ...   \n",
       "6  [['G17.035', 'L01.224.050'], ['E05.320'], ['E0...   \n",
       "7  [['E04.580.068'], ['E02.041.249', 'E05.008'], ...   \n",
       "8  [['D03.633.100.759.646.138.124', 'D13.695.667....   \n",
       "9  [['N05.715.360.300.179'], ['I01.451.227'], ['C...   \n",
       "\n",
       "                                            meshroot  A  B  C  D  E  F  G  H  \\\n",
       "0  ['Chemicals and Drugs [D]', 'Organisms [B]', '...  0  1  1  1  1  0  0  1   \n",
       "1  ['Named Groups [M]', 'Chemicals and Drugs [D]'...  0  1  1  1  1  1  1  0   \n",
       "2  ['Phenomena and Processes [G]', 'Information S...  1  1  0  1  1  0  1  0   \n",
       "3  ['Chemicals and Drugs [D]', 'Technology, Indus...  1  1  1  1  1  0  1  0   \n",
       "4  ['Chemicals and Drugs [D]', 'Phenomena and Pro...  1  1  0  1  1  0  1  0   \n",
       "5  ['Psychiatry and Psychology [F]', 'Phenomena a...  0  1  0  0  0  1  1  0   \n",
       "6  ['Phenomena and Processes [G]', 'Information S...  0  0  0  0  1  0  1  0   \n",
       "7  ['Analytical, Diagnostic and Therapeutic Techn...  0  1  1  1  1  1  0  0   \n",
       "8  ['Chemicals and Drugs [D]', 'Organisms [B]', '...  1  1  0  1  0  0  0  1   \n",
       "9  ['Health Care [N]', 'Anthropology, Education, ...  0  1  1  0  0  0  1  0   \n",
       "\n",
       "   I  J  L  M  N  Z  \n",
       "0  0  0  0  0  0  0  \n",
       "1  1  1  0  1  1  1  \n",
       "2  0  0  1  0  0  0  \n",
       "3  0  1  0  0  0  0  \n",
       "4  0  1  0  0  0  0  \n",
       "5  0  0  0  0  0  1  \n",
       "6  1  1  1  0  1  1  \n",
       "7  0  0  0  1  1  0  \n",
       "8  0  0  0  0  0  0  \n",
       "9  1  0  0  0  1  1  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv('../data/PubMed-multi-label-dataset.csv')\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "24be94da-6317-4a04-a35b-64b14174134b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 20 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   Title         49998 non-null  object\n",
      " 1   abstractText  50000 non-null  object\n",
      " 2   meshMajor     50000 non-null  object\n",
      " 3   pmid          50000 non-null  int64 \n",
      " 4   meshid        50000 non-null  object\n",
      " 5   meshroot      50000 non-null  object\n",
      " 6   A             50000 non-null  int64 \n",
      " 7   B             50000 non-null  int64 \n",
      " 8   C             50000 non-null  int64 \n",
      " 9   D             50000 non-null  int64 \n",
      " 10  E             50000 non-null  int64 \n",
      " 11  F             50000 non-null  int64 \n",
      " 12  G             50000 non-null  int64 \n",
      " 13  H             50000 non-null  int64 \n",
      " 14  I             50000 non-null  int64 \n",
      " 15  J             50000 non-null  int64 \n",
      " 16  L             50000 non-null  int64 \n",
      " 17  M             50000 non-null  int64 \n",
      " 18  N             50000 non-null  int64 \n",
      " 19  Z             50000 non-null  int64 \n",
      "dtypes: int64(15), object(5)\n",
      "memory usage: 7.6+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9699c7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=data.iloc[:,2].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ac4b4bc9-aacd-43a8-8969-0a4182c127d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 14)\n"
     ]
    }
   ],
   "source": [
    "Y = data.iloc[:, 6:20].to_numpy(dtype=int)\n",
    "print(Y.shape)  # MUST be (50000, 14)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9cf78e2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille du corpus : 50000\n"
     ]
    }
   ],
   "source": [
    "print('Taille du corpus : {0:d}'.format(len(corpus)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65fda3e6",
   "metadata": {},
   "source": [
    "### Ici vous pouvez traiter de votre corpus si vous le souhaitez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "728f794a-1e5c-42ef-a459-2c30cbe8efe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#entrainement du model Word2vec sur la colonnes abstracts "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7035b4a",
   "metadata": {},
   "source": [
    "<h1 align=center><font size = 5 color='blue'>Découpage de la base en Apprentissage et Test</font></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4ad7d1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_train,corpus_test,y_train,y_test=train_test_split(corpus,Y,test_size=0.33,shuffle=True,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c0e493af-b096-4b4f-ac38-9226a5478d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "corpus_train_tokens = [\n",
    "    gensim.utils.simple_preprocess(text) for text in corpus_train\n",
    "]\n",
    "\n",
    "corpus_test_tokens = [\n",
    "    gensim.utils.simple_preprocess(text) for text in corpus_test\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e7cbed9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exemple du 1er texte du Train : ['animals', 'cytokines', 'endometrium', 'escherichia', 'coli', 'female', 'goats', 'immunity', 'innate', 'neutrophils', 'postpartum', 'period', 'rna', 'messenger', 'toll', 'like', 'receptor', 'up', 'regulation', 'uterus', 'beta', 'defensins']\n"
     ]
    }
   ],
   "source": [
    "print(\"Exemple du 1er texte du Train :\", corpus_train_tokens[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889f8765",
   "metadata": {},
   "source": [
    "<h1 align=center><font size = 5 color='blue'>Développement d'un LSTM utilisant le Word2Vec entraine </font></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d8bf58f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_wv_entraine=gensim.models.Word2Vec.load('modele/word2vec_entraine.h5')\n",
    "model=model_wv_entraine.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "03c506bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille du vecteur d'embedding du modèle Google Word2Vec : 200\n",
      "Taille du vocabulaire du modèle Word2Vec : 12416\n"
     ]
    }
   ],
   "source": [
    "print(\"Taille du vecteur d'embedding du modèle Google Word2Vec :\", model.vector_size)\n",
    "print(\"Taille du vocabulaire du modèle Word2Vec :\", len(model.index_to_key))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ba0d8f",
   "metadata": {},
   "source": [
    "<h1 align=left><font size = 4 color='Green'>Préparation des textes pour le modèle LSTM</font></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9cb80b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exemple du 1er texte du train : ['animals', 'cytokines', 'endometrium', 'escherichia', 'coli', 'female', 'goats', 'immunity', 'innate', 'neutrophils', 'postpartum', 'period', 'rna', 'messenger', 'toll', 'like', 'receptor', 'up', 'regulation', 'uterus', 'beta', 'defensins']\n",
      "1er texte du train converti en indices : [5, 480, 2099, 184, 179, 3, 2118, 656, 1667, 711, 2238, 613, 37, 147, 1301, 450, 122, 62, 51, 1357, 119, 4575]\n"
     ]
    }
   ],
   "source": [
    "# Cette fonction Convertit un texte (liste de mots) en séquence d'indices selon le dictionnaire fourni. \n",
    "# Seuls les mots présents dans le dictionnaire sont conservés\n",
    "def to_sequence(index, text):\n",
    "    indexes = [index[word] for word in text if word in index]\n",
    "    return indexes\n",
    "\n",
    "word2idx = {word: idx for idx, word in enumerate(model.index_to_key)}\n",
    "X_train_sequences = [to_sequence(word2idx, x) for x in corpus_train_tokens]\n",
    "X_test_sequences = [to_sequence(word2idx, x) for x in corpus_test_tokens]\n",
    "\n",
    "print(\"Exemple du 1er texte du train :\", corpus_train_tokens[0])\n",
    "print(\"1er texte du train converti en indices :\", X_train_sequences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "48672a62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longueur du texte du Train le plus long :  106 tokens\n"
     ]
    }
   ],
   "source": [
    "print(\"Longueur du texte du Train le plus long : \",max([len(X_train_sequences[i]) for i in range(len(X_train_sequences))]),\"tokens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "fc64e0eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1er texte du train, indexé et ramené à 50 tokens (en gardant les derniers) :\n",
      " [12416 12416 12416 12416 12416 12416 12416 12416 12416 12416 12416 12416\n",
      " 12416 12416 12416 12416 12416 12416 12416 12416 12416 12416 12416 12416\n",
      " 12416 12416 12416 12416     5   480  2099   184   179     3  2118   656\n",
      "  1667   711  2238   613    37   147  1301   450   122    62    51  1357\n",
      "   119  4575]\n"
     ]
    }
   ],
   "source": [
    "MAX_SEQ_LENGHT=50 # Longueur maximale des séquences (nombre de tokens conservés)\n",
    "N_FEATURES = len(model.index_to_key)\n",
    "# Padding ou troncature des séquences à une longueur fixe de 50 tokens.\n",
    "# Si la séquence est plus longue : on garde les 50 derniers tokens.\n",
    "# Si elle est plus courte : on ajoute du padding avec la valeur \"N_FEATURES\".\n",
    "X_train_sequences = pad_sequences(X_train_sequences, maxlen=MAX_SEQ_LENGHT, value=N_FEATURES)\n",
    "X_test_sequences = pad_sequences(X_test_sequences, maxlen=MAX_SEQ_LENGHT, value=N_FEATURES)\n",
    "print(\"1er texte du train, indexé et ramené à 50 tokens (en gardant les derniers) :\\n\", X_train_sequences[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d2d8d5",
   "metadata": {},
   "source": [
    "<h1 align=left><font size = 4 color='Green'>Création de la matrice d'embedding</font></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "be376b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille de la matrice d'embedding (vocab_size + 1, embedding_dim) : (12417, 200)\n"
     ]
    }
   ],
   "source": [
    "# Taille des vecteurs d'embedding produits par le modèle Google Word2Vec\n",
    "EMBEDDINGS_LEN = model.vector_size\n",
    "# Création d'une matrice d'embeddings initialisée à zéro\n",
    "# Chaque ligne correspond à un mot du vocabulaire, et chaque colonne à une dimension de l'embedding\n",
    "# On ajoute une ligne supplémentaire à la fin pour le padding (index hors vocabulaire)\n",
    "\n",
    "embeddings_index = np.zeros((len(model.index_to_key)+1, EMBEDDINGS_LEN))\n",
    "# Remplissage de la matrice avec les vecteurs du modèle Word2Vec\n",
    "# La dernière ligne reste à zéro pour représenter les tokens de padding\n",
    "\n",
    "embeddings_index[:-1,:]=model.vectors\n",
    "print(\"Taille de la matrice d'embedding (vocab_size + 1, embedding_dim) :\", embeddings_index.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2644095d",
   "metadata": {},
   "source": [
    "<h1 align=left><font size = 4 color='Green'>Création de l'architecture du modèle LSTM</font></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f649f679",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,483,400</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_5 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │     \u001b[38;5;34m2,483,400\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_5 (\u001b[38;5;33mLSTM\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,483,400</span> (9.47 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,483,400\u001b[0m (9.47 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,483,400</span> (9.47 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,483,400\u001b[0m (9.47 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_lstm = Sequential()\n",
    "\n",
    "model_lstm.add(Embedding(\n",
    "    input_dim=len(model.key_to_index) + 1,\n",
    "    output_dim=EMBEDDINGS_LEN,\n",
    "    weights=[embeddings_index],\n",
    "    trainable=True\n",
    "))\n",
    "\n",
    "model_lstm.add(LSTM(100, dropout=0.2))\n",
    "\n",
    "# ✅ 14 outputs (one per label)\n",
    "model_lstm.add(Dense(14, activation='sigmoid'))\n",
    "\n",
    "model_lstm.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']  # OK for training only\n",
    ")\n",
    "\n",
    "model_lstm.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83c9722",
   "metadata": {},
   "source": [
    "<h1 align=left><font size = 4 color='Green'>Entraînement du modèle LSTM</font></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ad7de0ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 132ms/step - accuracy: 0.3099 - loss: 0.3534 - val_accuracy: 0.3027 - val_loss: 0.2631\n",
      "Epoch 2/10\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 125ms/step - accuracy: 0.2612 - loss: 0.2474 - val_accuracy: 0.2266 - val_loss: 0.2218\n",
      "Epoch 3/10\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 120ms/step - accuracy: 0.2074 - loss: 0.2124 - val_accuracy: 0.2260 - val_loss: 0.1969\n",
      "Epoch 4/10\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 125ms/step - accuracy: 0.1885 - loss: 0.1900 - val_accuracy: 0.1725 - val_loss: 0.1811\n",
      "Epoch 5/10\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 125ms/step - accuracy: 0.1586 - loss: 0.1732 - val_accuracy: 0.1615 - val_loss: 0.1697\n",
      "Epoch 6/10\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 124ms/step - accuracy: 0.1626 - loss: 0.1596 - val_accuracy: 0.1493 - val_loss: 0.1576\n",
      "Epoch 7/10\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 124ms/step - accuracy: 0.1482 - loss: 0.1474 - val_accuracy: 0.1284 - val_loss: 0.1505\n",
      "Epoch 8/10\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 124ms/step - accuracy: 0.1456 - loss: 0.1374 - val_accuracy: 0.1433 - val_loss: 0.1446\n",
      "Epoch 9/10\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 124ms/step - accuracy: 0.1475 - loss: 0.1284 - val_accuracy: 0.1364 - val_loss: 0.1371\n",
      "Epoch 10/10\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 124ms/step - accuracy: 0.1486 - loss: 0.1198 - val_accuracy: 0.1501 - val_loss: 0.1333\n"
     ]
    }
   ],
   "source": [
    "history = model_lstm.fit(X_train_sequences, y_train, epochs=10, batch_size=128, verbose=1,validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "cf401eef-a849-49d4-872d-8b32d01b72a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 18ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_proba = model_lstm.predict(X_test_sequences)\n",
    "y_pred = (y_pred_proba >= 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "576ef4f0-03a3-4985-bd9b-bbf045e1fdcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Macro sur le jeu de test : 0.8956500197018678\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "print(\"F1 Macro sur le jeu de test :\", f1_macro)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "99234797-fe55-4651-b527-d6c399715653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9172    0.8996    0.9083      7680\n",
      "           1     0.9858    0.9926    0.9892     15364\n",
      "           2     0.9549    0.9084    0.9310      8710\n",
      "           3     0.9704    0.9478    0.9590     10409\n",
      "           4     0.9631    0.9362    0.9495     12877\n",
      "           5     0.9431    0.8777    0.9092      2910\n",
      "           6     0.9425    0.9319    0.9372     11159\n",
      "           7     0.8367    0.5291    0.6483      1975\n",
      "           8     0.8637    0.6918    0.7682      1804\n",
      "           9     0.8819    0.6937    0.7765      1851\n",
      "          10     0.9682    0.8671    0.9149      2461\n",
      "          11     0.9838    0.9835    0.9837      6917\n",
      "          12     0.9684    0.9559    0.9621      7468\n",
      "          13     0.9436    0.8639    0.9020      2652\n",
      "\n",
      "   micro avg     0.9571    0.9220    0.9392     94237\n",
      "   macro avg     0.9374    0.8628    0.8957     94237\n",
      "weighted avg     0.9554    0.9220    0.9373     94237\n",
      " samples avg     0.9573    0.9187    0.9323     94237\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred, digits=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "9af3424b-3400-4588-8b94-bb7985aeaf14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold 0.3: F1-macro = 0.9006\n",
      "Threshold 0.4: F1-macro = 0.9006\n",
      "Threshold 0.5: F1-macro = 0.8957\n",
      "Threshold 0.6: F1-macro = 0.8864\n"
     ]
    }
   ],
   "source": [
    "for t in [0.3, 0.4, 0.5, 0.6]:\n",
    "    y_pred = (y_pred_proba >= t).astype(int)\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "    print(f\"Threshold {t}: F1-macro = {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a018ac16-68a9-4b5d-a4f4-a6eb3da1a86d",
   "metadata": {},
   "source": [
    "# Checking for overfitting of the lstm model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "22897164-960e-45e3-a030-8ff2e7532928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1047/1047\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 15ms/step\n",
      "Train Macro F1: 0.9285021908119307\n",
      "Test  Macro F1: 0.8956500197018678\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = (model_lstm.predict(X_train_sequences) >= 0.5).astype(int)\n",
    "train_f1 = f1_score(y_train, y_train_pred, average='macro')\n",
    "\n",
    "print(\"Train Macro F1:\", train_f1)\n",
    "print(\"Test  Macro F1:\", f1_macro)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770b11ec-ef99-4b13-9f32-171ddc0dc82a",
   "metadata": {},
   "source": [
    "The model achieves a Macro F1-score of 0.93 on the training set and 0.90 on the test set. The small performance gap indicates good generalization and no significant overfitting, despite the relatively large number of parameters induced by the embedding layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee2020d",
   "metadata": {},
   "source": [
    "<h1 align=left><font size = 4 color='Green'>Évaluation du modèle LSTM sur les données de test</font></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5908b6f",
   "metadata": {},
   "source": [
    "<h1 align=center><font size = 5 color='blue'>Bonus</font></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa8ed6f",
   "metadata": {},
   "source": [
    "<h1 align=left><font size = 4 color='Green'>Utilisation de la sortie des LSTM dans d'autres modèles ML</font></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ea620b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<Embedding name=embedding_5, built=True>, <LSTM name=lstm_5, built=True>, <Dense name=dense_4, built=True>]\n",
      "\u001b[1m1047/1047\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 17ms/step\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step\n",
      "(33500, 100)\n"
     ]
    }
   ],
   "source": [
    "# Affichage des différentes couches du modèle LSTM\n",
    "print(model_lstm.layers)\n",
    "\n",
    "# Utilisation d'un modèle dont la sortie correspond à la couche LSTM après l'Embedding\n",
    "Model_embedding_texts_LSTM = Model(inputs=model_lstm.inputs, outputs=model_lstm.layers[1].output)\n",
    "\n",
    "# Sauvegarde du modèle intermédiaire pour générer des features\n",
    "Model_embedding_texts_LSTM.save('../models/model_lstm_features.h5')\n",
    "\n",
    "# Génération des représentations vectorielles (features) des textes d'entraînement à utiliser pour un fit de votre modèle ML \n",
    "corpus_train_lstm = Model_embedding_texts_LSTM.predict(X_train_sequences)\n",
    "\n",
    "# Génération des représentations vectorielles des textes de test à utiliser pour un predict avec votre modèle ML\n",
    "corpus_test_lstm = Model_embedding_texts_LSTM.predict(X_test_sequences)\n",
    "\n",
    "# Affichage de la forme des features générées pour le train\n",
    "print(corpus_train_lstm.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b3d93b-188e-4dfb-9ec8-3c44d2cc2520",
   "metadata": {},
   "source": [
    "# Bonus : BI-LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4413ed5e-b379-4de7-ae30-45b4650f604d",
   "metadata": {},
   "source": [
    "<h1 align=left><font size = 4 color='Green'>Création de larchitecture du modèle BI-LSTM</font></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bea6ec0b-724c-4188-9c0c-b57636a79676",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bi= Sequential([\n",
    "    Embedding(\n",
    "        input_dim=len(model.key_to_index) + 1,\n",
    "        output_dim=EMBEDDINGS_LEN,\n",
    "        weights=[embeddings_index],\n",
    "        trainable=True\n",
    "    ),\n",
    "\n",
    "    Bidirectional(\n",
    "        LSTM(100, recurrent_dropout=0.2),\n",
    "        merge_mode='concat'\n",
    "    ),\n",
    "\n",
    "\n",
    "    Dense(14, activation='sigmoid')  # multi-label\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9a18f5cd-38cc-47ef-b3d3-915a2e48a6a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,483,400</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">240,800</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,814</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_4 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m200\u001b[0m)        │     \u001b[38;5;34m2,483,400\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)            │       \u001b[38;5;34m240,800\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m)             │         \u001b[38;5;34m2,814\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,727,014</span> (10.40 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,727,014\u001b[0m (10.40 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,727,014</span> (10.40 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,727,014\u001b[0m (10.40 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_bi.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']  # OK for training only\n",
    ")\n",
    "\n",
    "model_bi.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8f59c166-4d60-4de8-b370-c087c4c622a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 120ms/step - accuracy: 0.1826 - loss: 0.0468 - val_accuracy: 0.2051 - val_loss: 0.1509\n",
      "Epoch 2/10\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 117ms/step - accuracy: 0.1901 - loss: 0.0379 - val_accuracy: 0.1755 - val_loss: 0.1545\n",
      "Epoch 3/10\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 117ms/step - accuracy: 0.1898 - loss: 0.0314 - val_accuracy: 0.1833 - val_loss: 0.1566\n",
      "Epoch 4/10\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 151ms/step - accuracy: 0.1951 - loss: 0.0269 - val_accuracy: 0.2012 - val_loss: 0.1612\n",
      "Epoch 5/10\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 158ms/step - accuracy: 0.2000 - loss: 0.0226 - val_accuracy: 0.2042 - val_loss: 0.1635\n",
      "Epoch 6/10\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 166ms/step - accuracy: 0.2048 - loss: 0.0186 - val_accuracy: 0.2155 - val_loss: 0.1677\n",
      "Epoch 7/10\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 162ms/step - accuracy: 0.2132 - loss: 0.0165 - val_accuracy: 0.2313 - val_loss: 0.1730\n",
      "Epoch 8/10\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 151ms/step - accuracy: 0.2189 - loss: 0.0139 - val_accuracy: 0.2328 - val_loss: 0.1722\n",
      "Epoch 9/10\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 156ms/step - accuracy: 0.2313 - loss: 0.0124 - val_accuracy: 0.2427 - val_loss: 0.1753\n",
      "Epoch 10/10\n",
      "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 172ms/step - accuracy: 0.2380 - loss: 0.0105 - val_accuracy: 0.2540 - val_loss: 0.1804\n"
     ]
    }
   ],
   "source": [
    "history_bi= model_bi.fit(X_train_sequences, y_train, epochs=10, batch_size=128, verbose=1,validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "564e98ce-394e-465c-89e0-2f8343171557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_proba_bi = model_bi.predict(X_test_sequences)\n",
    "y_pred = (y_pred_proba_bi >= 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b0e911f6-03c2-42db-b849-2857a7f191a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Macro sur le jeu de test : 0.8915017917142963\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "print(\"F1 Macro sur le jeu de test :\", f1_macro)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0034a0ee-eb22-40a4-9aa9-594b29426d90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold 0.3: F1-macro = 0.8951\n",
      "Threshold 0.4: F1-macro = 0.8948\n",
      "Threshold 0.5: F1-macro = 0.8915\n",
      "Threshold 0.6: F1-macro = 0.8858\n"
     ]
    }
   ],
   "source": [
    "for t in [0.3, 0.4, 0.5, 0.6]:\n",
    "    y_pred = (y_pred_proba_bi >= t).astype(int)\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "    print(f\"Threshold {t}: F1-macro = {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db87c730-4085-489d-820b-5d424773aa39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
